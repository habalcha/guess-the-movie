{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "import json \n",
    "import ndjson\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories <class 'pandas.core.series.Series'>\n",
      "cruise ship\n",
      "penguin\n",
      "spider\n",
      "hammer\n",
      "lion\n",
      "whale\n",
      "shark\n",
      "monkey\n",
      "ocean\n",
      "snake\n",
      "dragon\n",
      "panda\n",
      "tiger\n",
      "zebra\n",
      "giraffe\n",
      "Total categories=  15\n"
     ]
    }
   ],
   "source": [
    "def load_movies(name):\n",
    "    df = pd.read_csv(name)\n",
    "    df['keywords'] = df['keywords'].apply(json.loads)\n",
    "    return df\n",
    "\n",
    "def edit_names(keywords):\n",
    "    return','.join([x['name'] for x in keywords]) \n",
    "\n",
    "#gets the category name from the ndjson file name\n",
    "def get_category_from_filename(filename):\n",
    "    i = filename.rfind('_')\n",
    "    filename = filename[i+1:-7]\n",
    "    return filename\n",
    "\n",
    "df_categories = pd.read_csv('Categories_List.csv')\n",
    "#print(df_categories)\n",
    "\n",
    "movies = load_movies('MoviesList.csv')\n",
    "tmdb_movies = movies.copy()\n",
    "tmdb_movies['keywords'] = tmdb_movies['keywords'].apply(edit_names)\n",
    "\n",
    "df_categories = pd.read_csv('Categories_List.csv')# file with 345 category names\n",
    "movies = load_movies('MoviesList.csv')\n",
    "tmdb_movies = movies.copy()\n",
    "tmdb_movies['keywords'] = tmdb_movies['keywords'].apply(edit_names)\n",
    "\n",
    "categories = df_categories['Categories']\n",
    "print(\"Categories\", type(categories))\n",
    "categories_set = set()\n",
    "categories_new_set = set()\n",
    "\n",
    "for obj in tmdb_movies['keywords']:\n",
    "    list = obj.split(',')\n",
    "    categories_set.update(list)\n",
    "\n",
    "# prints the matching categories: Download the files as required\n",
    "for value in categories_set:\n",
    "    # if categories.str.contains(value).any(): ->partial match\n",
    "    if categories.eq(value).any():  # exact match string\n",
    "        print(value)\n",
    "        categories_new_set.add(value)\n",
    "\n",
    "category_count = len(categories_new_set)\n",
    "print(\"Total categories= \", len(categories_new_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "movies_df = load_movies('MoviesList.csv') #dataframe\n",
    "categories_list = categories.tolist()\n",
    "\n",
    "with open('MoviesListEdited.csv', 'w') as csvfile:\n",
    "    filewriter = csv.writer(csvfile, delimiter=',')\n",
    "    filewriter.writerow(['Name', 'Keywords'])\n",
    "    for index, row in movies_df.iterrows():\n",
    "        name = row[\"original_title\"]\n",
    "        keywords_list = [ sub['name'] for sub in row[\"keywords\"] ] \n",
    "        new_list = set(keywords_list) & set(categories_list)\n",
    "        filewriter.writerow([name, new_list])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file cruise ship.......\n",
      "Reading file dragon.......\n",
      "Reading file giraffe.......\n",
      "Reading file hammer.......\n",
      "Reading file lion.......\n",
      "Reading file monkey.......\n",
      "Reading file ocean.......\n",
      "Reading file panda.......\n",
      "Reading file penguin.......\n",
      "Reading file shark.......\n",
      "Reading file snake.......\n",
      "Reading file spider.......\n",
      "Reading file tiger.......\n",
      "Reading file whale.......\n",
      "Reading file zebra.......\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "doodle_dict = dict()\n",
    "doodles_df = pd.DataFrame()\n",
    "path = './Doodle_ndjson'  # directory to store all ndjson files\n",
    "\n",
    "# reads each ndjson one by one from 'Doodle_ndjson' directory\n",
    "for file in os.listdir(path):\n",
    "    data_new = []\n",
    "    data = []\n",
    "\n",
    "    filename = get_category_from_filename(file)\n",
    "    print(\"Reading file \"+filename+\".......\")\n",
    "\n",
    "    #going through all the files in Doodle_ndjson directory\n",
    "    with open(path+\"/\"+file) as f:\n",
    "        data = ndjson.load(f)  # loads an ndjson as list of doodle data # data[listitem] is <class 'dict'>\n",
    "        for listitem in range(len(data)):\n",
    "            # ignoring the items if 'recognized' is False\n",
    "            if data[listitem]['recognized'] != False:\n",
    "                data_new.append(data[listitem].get('drawing'))\n",
    "\n",
    "    # Randomly selecting 100 items from a doodle data list\n",
    "    data = random.sample(data_new, 100)\n",
    "    # adding each data list to dictionary <key = category_name> <value = data>\n",
    "    doodle_dict[filename] = data\n",
    "\n",
    "print('Done!')\n",
    "#print(doodle_dict['shark']) #to see format of one entry in dict\n",
    "###################################\n",
    "# There is no data for ship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[61, 60, 86, 143, 217, 247, 249, 255],\n",
       "  [141, 138, 136, 138, 143, 151, 128, 103]],\n",
       " [[64, 29, 0, 9, 41, 106, 205, 254], [142, 119, 94, 89, 89, 101, 96, 105]],\n",
       " [[31, 32, 35, 52, 100, 125, 128, 130, 125],\n",
       "  [91, 64, 60, 60, 70, 71, 73, 86, 108]],\n",
       " [[132, 116, 116, 120], [104, 26, 10, 0]]]"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doodle_dict_c = doodle_dict.copy()\n",
    "\n",
    "val = doodle_dict_c.get('cruise ship')\n",
    "\n",
    "# doodle_dict['cruise ship'] = val.pop(0)\n",
    "val[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_m = doodle_dict_c.get('monkey')\n",
    "len(val_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[10, 10, 14, 26, 36, 82, 165, 193, 219, 242, 255, 255, 250, 235, 173, 72, 0],\n",
       "  [92,\n",
       "   112,\n",
       "   127,\n",
       "   147,\n",
       "   156,\n",
       "   169,\n",
       "   183,\n",
       "   184,\n",
       "   174,\n",
       "   154,\n",
       "   116,\n",
       "   100,\n",
       "   88,\n",
       "   82,\n",
       "   86,\n",
       "   86,\n",
       "   82]],\n",
       " [[143, 154, 156, 163, 216, 224, 221], [83, 4, 0, 0, 10, 67, 86]],\n",
       " [[175, 175, 179, 204, 206, 203, 175], [31, 40, 42, 44, 41, 30, 32]]]"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doodle_dict_c['cruise ship']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cruise ship</th>\n",
       "      <th>dragon</th>\n",
       "      <th>giraffe</th>\n",
       "      <th>hammer</th>\n",
       "      <th>lion</th>\n",
       "      <th>monkey</th>\n",
       "      <th>ocean</th>\n",
       "      <th>panda</th>\n",
       "      <th>penguin</th>\n",
       "      <th>shark</th>\n",
       "      <th>snake</th>\n",
       "      <th>spider</th>\n",
       "      <th>tiger</th>\n",
       "      <th>whale</th>\n",
       "      <th>zebra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[0, 8, 18, 40, 61, 90, 107, 107, 19, 2], [47...</td>\n",
       "      <td>[[[116, 92, 77, 84, 107, 75, 82, 119], [10, 9,...</td>\n",
       "      <td>[[[24, 5, 0, 0, 10, 29, 54, 61, 68, 63, 71, 74...</td>\n",
       "      <td>[[[72, 61, 47], [255, 188, 63]], [[50, 50], [5...</td>\n",
       "      <td>[[[48, 48, 53, 83, 87, 87, 77, 114, 128, 109, ...</td>\n",
       "      <td>[[[57, 59, 69, 82, 101, 121, 145, 152, 170, 17...</td>\n",
       "      <td>[[[0, 11, 23, 40, 74], [3, 0, 8, 2, 2]], [[15,...</td>\n",
       "      <td>[[[52, 48, 41, 34, 30, 30, 45, 58, 74, 98, 121...</td>\n",
       "      <td>[[[71, 66, 67, 96, 107, 100, 79, 67], [71, 97,...</td>\n",
       "      <td>[[[107, 165, 228, 250, 255, 252, 221], [36, 31...</td>\n",
       "      <td>[[[0, 10, 36, 57, 69, 79, 86, 89, 92, 97, 116,...</td>\n",
       "      <td>[[[145, 138, 122, 87, 73, 71, 81, 90, 103, 111...</td>\n",
       "      <td>[[[76, 52, 24, 3, 0, 6, 37, 45, 52, 82, 106, 1...</td>\n",
       "      <td>[[[61, 119, 152, 193, 201, 209, 207, 197, 187,...</td>\n",
       "      <td>[[[71, 63, 57, 54, 60, 76, 84, 88, 82], [28, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[61, 60, 86, 143, 217, 247, 249, 255], [141,...</td>\n",
       "      <td>[[[54, 40, 0, 53, 32, 12, 26, 14, 42, 19, 27, ...</td>\n",
       "      <td>[[[81, 81, 92, 109, 174, 199, 218, 232, 222, 2...</td>\n",
       "      <td>[[[17, 3, 0, 0, 8, 30, 70, 137], [3, 6, 12, 29...</td>\n",
       "      <td>[[[6, 1, 3, 29], [113, 115, 120, 123]], [[23, ...</td>\n",
       "      <td>[[[44, 30, 18, 12, 12, 17, 36], [85, 93, 107, ...</td>\n",
       "      <td>[[[0, 67, 104, 128, 155, 196, 227, 255], [19, ...</td>\n",
       "      <td>[[[69, 61, 61, 71, 81, 93, 98, 102, 103, 92, 7...</td>\n",
       "      <td>[[[50, 51, 67, 84, 95, 99, 98, 88, 76, 64, 56,...</td>\n",
       "      <td>[[[115, 115, 133, 152, 162, 166, 165, 155, 136...</td>\n",
       "      <td>[[[255, 246, 177, 157, 116, 70, 54, 25, 13, 0,...</td>\n",
       "      <td>[[[123, 104, 97, 94, 101, 109, 127, 142, 146, ...</td>\n",
       "      <td>[[[20, 14, 7, 1, 20], [13, 12, 17, 37, 59]], [...</td>\n",
       "      <td>[[[130, 109, 81, 54, 27, 6, 0, 7, 25, 40, 77, ...</td>\n",
       "      <td>[[[64, 57, 52, 48, 51, 63, 78, 86, 87, 84, 77,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[2, 171, 249], [33, 33, 28]], [[0, 21, 167, ...</td>\n",
       "      <td>[[[34, 30, 39, 43, 50, 82, 83], [16, 3, 7, 2, ...</td>\n",
       "      <td>[[[24, 13, 0, 8, 32, 47, 57, 93, 108, 115, 136...</td>\n",
       "      <td>[[[62, 61, 67], [255, 211, 69]], [[68, 56, 37,...</td>\n",
       "      <td>[[[103, 87, 65, 54, 43, 43, 49, 63, 98, 123, 1...</td>\n",
       "      <td>[[[62, 32, 24, 19, 19, 27, 47, 77, 90, 103, 10...</td>\n",
       "      <td>[[[0, 33, 67, 72, 79, 85, 139, 158, 208, 230, ...</td>\n",
       "      <td>[[[55, 55, 59, 72, 81, 102, 129, 158, 175, 204...</td>\n",
       "      <td>[[[38, 61, 93, 103, 115, 126, 132, 141, 160, 1...</td>\n",
       "      <td>[[[167, 115, 99], [46, 41, 47]], [[123, 121, 1...</td>\n",
       "      <td>[[[0, 27, 34, 49, 60, 71, 110, 120, 139, 151, ...</td>\n",
       "      <td>[[[148, 133, 115, 101, 92, 91, 101, 113, 135, ...</td>\n",
       "      <td>[[[201, 182, 177, 176, 184, 204, 223, 234, 255...</td>\n",
       "      <td>[[[1, 5, 10, 28, 56, 86, 110, 119, 133, 151, 1...</td>\n",
       "      <td>[[[56, 54, 48, 65, 69, 64, 68], [114, 161, 189...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         cruise ship  \\\n",
       "0  [[[0, 8, 18, 40, 61, 90, 107, 107, 19, 2], [47...   \n",
       "1  [[[61, 60, 86, 143, 217, 247, 249, 255], [141,...   \n",
       "2  [[[2, 171, 249], [33, 33, 28]], [[0, 21, 167, ...   \n",
       "\n",
       "                                              dragon  \\\n",
       "0  [[[116, 92, 77, 84, 107, 75, 82, 119], [10, 9,...   \n",
       "1  [[[54, 40, 0, 53, 32, 12, 26, 14, 42, 19, 27, ...   \n",
       "2  [[[34, 30, 39, 43, 50, 82, 83], [16, 3, 7, 2, ...   \n",
       "\n",
       "                                             giraffe  \\\n",
       "0  [[[24, 5, 0, 0, 10, 29, 54, 61, 68, 63, 71, 74...   \n",
       "1  [[[81, 81, 92, 109, 174, 199, 218, 232, 222, 2...   \n",
       "2  [[[24, 13, 0, 8, 32, 47, 57, 93, 108, 115, 136...   \n",
       "\n",
       "                                              hammer  \\\n",
       "0  [[[72, 61, 47], [255, 188, 63]], [[50, 50], [5...   \n",
       "1  [[[17, 3, 0, 0, 8, 30, 70, 137], [3, 6, 12, 29...   \n",
       "2  [[[62, 61, 67], [255, 211, 69]], [[68, 56, 37,...   \n",
       "\n",
       "                                                lion  \\\n",
       "0  [[[48, 48, 53, 83, 87, 87, 77, 114, 128, 109, ...   \n",
       "1  [[[6, 1, 3, 29], [113, 115, 120, 123]], [[23, ...   \n",
       "2  [[[103, 87, 65, 54, 43, 43, 49, 63, 98, 123, 1...   \n",
       "\n",
       "                                              monkey  \\\n",
       "0  [[[57, 59, 69, 82, 101, 121, 145, 152, 170, 17...   \n",
       "1  [[[44, 30, 18, 12, 12, 17, 36], [85, 93, 107, ...   \n",
       "2  [[[62, 32, 24, 19, 19, 27, 47, 77, 90, 103, 10...   \n",
       "\n",
       "                                               ocean  \\\n",
       "0  [[[0, 11, 23, 40, 74], [3, 0, 8, 2, 2]], [[15,...   \n",
       "1  [[[0, 67, 104, 128, 155, 196, 227, 255], [19, ...   \n",
       "2  [[[0, 33, 67, 72, 79, 85, 139, 158, 208, 230, ...   \n",
       "\n",
       "                                               panda  \\\n",
       "0  [[[52, 48, 41, 34, 30, 30, 45, 58, 74, 98, 121...   \n",
       "1  [[[69, 61, 61, 71, 81, 93, 98, 102, 103, 92, 7...   \n",
       "2  [[[55, 55, 59, 72, 81, 102, 129, 158, 175, 204...   \n",
       "\n",
       "                                             penguin  \\\n",
       "0  [[[71, 66, 67, 96, 107, 100, 79, 67], [71, 97,...   \n",
       "1  [[[50, 51, 67, 84, 95, 99, 98, 88, 76, 64, 56,...   \n",
       "2  [[[38, 61, 93, 103, 115, 126, 132, 141, 160, 1...   \n",
       "\n",
       "                                               shark  \\\n",
       "0  [[[107, 165, 228, 250, 255, 252, 221], [36, 31...   \n",
       "1  [[[115, 115, 133, 152, 162, 166, 165, 155, 136...   \n",
       "2  [[[167, 115, 99], [46, 41, 47]], [[123, 121, 1...   \n",
       "\n",
       "                                               snake  \\\n",
       "0  [[[0, 10, 36, 57, 69, 79, 86, 89, 92, 97, 116,...   \n",
       "1  [[[255, 246, 177, 157, 116, 70, 54, 25, 13, 0,...   \n",
       "2  [[[0, 27, 34, 49, 60, 71, 110, 120, 139, 151, ...   \n",
       "\n",
       "                                              spider  \\\n",
       "0  [[[145, 138, 122, 87, 73, 71, 81, 90, 103, 111...   \n",
       "1  [[[123, 104, 97, 94, 101, 109, 127, 142, 146, ...   \n",
       "2  [[[148, 133, 115, 101, 92, 91, 101, 113, 135, ...   \n",
       "\n",
       "                                               tiger  \\\n",
       "0  [[[76, 52, 24, 3, 0, 6, 37, 45, 52, 82, 106, 1...   \n",
       "1  [[[20, 14, 7, 1, 20], [13, 12, 17, 37, 59]], [...   \n",
       "2  [[[201, 182, 177, 176, 184, 204, 223, 234, 255...   \n",
       "\n",
       "                                               whale  \\\n",
       "0  [[[61, 119, 152, 193, 201, 209, 207, 197, 187,...   \n",
       "1  [[[130, 109, 81, 54, 27, 6, 0, 7, 25, 40, 77, ...   \n",
       "2  [[[1, 5, 10, 28, 56, 86, 110, 119, 133, 151, 1...   \n",
       "\n",
       "                                               zebra  \n",
       "0  [[[71, 63, 57, 54, 60, 76, 84, 88, 82], [28, 2...  \n",
       "1  [[[64, 57, 52, 48, 51, 63, 78, 86, 87, 84, 77,...  \n",
       "2  [[[56, 54, 48, 65, 69, 64, 68], [114, 161, 189...  "
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(doodle_dict[\"whale\"]) #to see format of one entry in dict\n",
    "#print(doodle_dict['whale'])\n",
    "doodles_df = pd.DataFrame(doodle_dict)\n",
    "doodles_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# multiple images of a category are stored under one column\n",
    "\n",
    "x = doodles_df.iloc[20, 5]\n",
    "x_length = len(x)\n",
    "\n",
    "for i in range(x_length):\n",
    "    plt.plot(x[i][0], x[i][1])\n",
    "    plt.axis('off')\n",
    "  \n",
    "plt.savefig('shark_1.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = doodles_df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>sketch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cruise ship</td>\n",
       "      <td>[[[0, 8, 18, 40, 61, 90, 107, 107, 19, 2], [47...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cruise ship</td>\n",
       "      <td>[[[61, 60, 86, 143, 217, 247, 249, 255], [141,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cruise ship</td>\n",
       "      <td>[[[2, 171, 249], [33, 33, 28]], [[0, 21, 167, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cruise ship</td>\n",
       "      <td>[[[3, 34, 114, 249, 252, 254, 249, 207, 204, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cruise ship</td>\n",
       "      <td>[[[12, 13, 24, 52, 96, 157, 190, 218, 242, 243...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>zebra</td>\n",
       "      <td>[[[153, 163, 197, 213, 223, 244, 252, 255, 244...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>zebra</td>\n",
       "      <td>[[[33, 4, 0, 3, 13, 40, 62, 73, 72, 84, 90, 92...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>zebra</td>\n",
       "      <td>[[[14, 8, 4, 4, 10, 15, 22, 27, 40, 47, 75, 80...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>zebra</td>\n",
       "      <td>[[[12, 3, 0, 4, 25], [23, 28, 37, 40, 41]], [[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>zebra</td>\n",
       "      <td>[[[68, 66, 69], [96, 56, 44]], [[47, 48, 45], ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          keyword                                             sketch\n",
       "0     cruise ship  [[[0, 8, 18, 40, 61, 90, 107, 107, 19, 2], [47...\n",
       "1     cruise ship  [[[61, 60, 86, 143, 217, 247, 249, 255], [141,...\n",
       "2     cruise ship  [[[2, 171, 249], [33, 33, 28]], [[0, 21, 167, ...\n",
       "3     cruise ship  [[[3, 34, 114, 249, 252, 254, 249, 207, 204, 1...\n",
       "4     cruise ship  [[[12, 13, 24, 52, 96, 157, 190, 218, 242, 243...\n",
       "...           ...                                                ...\n",
       "1495        zebra  [[[153, 163, 197, 213, 223, 244, 252, 255, 244...\n",
       "1496        zebra  [[[33, 4, 0, 3, 13, 40, 62, 73, 72, 84, 90, 92...\n",
       "1497        zebra  [[[14, 8, 4, 4, 10, 15, 22, 27, 40, 47, 75, 80...\n",
       "1498        zebra  [[[12, 3, 0, 4, 25], [23, 28, 37, 40, 41]], [[...\n",
       "1499        zebra  [[[68, 66, 69], [96, 56, 44]], [[47, 48, 45], ...\n",
       "\n",
       "[1500 rows x 2 columns]"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df1 = df1.reset_index()\n",
    "# y = df1.iloc[:, 0]\n",
    "# x = df1.iloc[:, 1:]\n",
    "# x.shape\n",
    "df1 = df1.stack()\n",
    "df1 = df1.reset_index()\n",
    "df1 = df1.drop('level_1', axis = 1)\n",
    "df1.columns = ['keyword', 'sketch']\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[61, 60, 86, 143, 217, 247, 249, 255],\n",
       " [141, 138, 136, 138, 143, 151, 128, 103]]"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.loc[1, 'sketch'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1008    [[[2, 3, 18, 85, 94, 114, 125, 140, 241], [20,...\n",
       "678     [[[0, 21, 52, 90, 163, 220], [12, 10, 0, 11, 9...\n",
       "1123    [[[117, 105, 85, 67, 63, 72, 85, 118, 151, 157...\n",
       "1028    [[[121, 104, 95, 71, 62, 43, 33, 29, 31, 46, 7...\n",
       "1031    [[[4, 0, 2, 11, 30, 54, 81, 115, 172, 207, 216...\n",
       "                              ...                        \n",
       "1000    [[[0, 10, 36, 57, 69, 79, 86, 89, 92, 97, 116,...\n",
       "487     [[[131, 126, 117, 97, 88, 80, 77, 78, 82, 100,...\n",
       "93      [[[42, 53], [43, 83]], [[43, 51, 72, 89, 105, ...\n",
       "418     [[[127, 115, 101, 77, 60, 47, 38, 29, 35, 46, ...\n",
       "1164    [[[117, 106, 75, 68, 61, 60, 68, 81, 97, 135, ...\n",
       "Name: sketch, Length: 1050, dtype: object"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_x and train_y, test_x and test_y\n",
    "\n",
    "from sklearn import model_selection\n",
    "train_x, test_x,  train_y, test_y = model_selection.train_test_split(df1.sketch, df1.keyword, test_size = 0.3)\n",
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1050,)"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to reshape train and test x datas\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0, 8, 18, 40, 61, 90, 107, 107, 19, 2],\n",
       "  [47, 71, 85, 96, 98, 82, 65, 60, 51, 46]],\n",
       " [[41, 41], [52, 31]],\n",
       " [[52, 52], [55, 31]],\n",
       " [[55, 55, 49, 34, 34], [37, 3, 0, 2, 35]],\n",
       " [[30, 54], [36, 32]],\n",
       " [[56, 78, 77, 68, 63, 50], [31, 61, 32, 10, 4, 2]],\n",
       " [[29, 29], [14, 14]],\n",
       " [[140, 143, 156, 185, 205, 217, 237, 254, 255, 251],\n",
       "  [51, 65, 81, 99, 103, 99, 80, 40, 32, 29]]]"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grab a picture data\n",
    "\n",
    "picture = train_x[0]\n",
    "train_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 2, 2, 5, 2, 6, 2, 10]"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the length of all the individual drawings of the picture\n",
    "sketch_length = []\n",
    "for draw in picture:\n",
    "    sketch_length.append(len(draw[0]))\n",
    "\n",
    "total_points = sum(sketch_length)\n",
    "sketch_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 3)"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a blank array that takes the x, y and end points of the picture\n",
    "\n",
    "pic_array = np.zeros((total_points, 3), dtype = np.float32)\n",
    "pic_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do through each line of drawing and put it as the x and y values of the empty array.\n",
    "# if at the last list, mark the 3rd column as 1 (1 = end).\n",
    "\n",
    "position = 0\n",
    "\n",
    "for draw in picture:\n",
    "    for i in [0, 1]:\n",
    "        pic_array[position:(position + len(draw[0])), i] = draw[i]\n",
    "    position += len(draw[0])\n",
    "    pic_array[position-1, 2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,  47.,   0.],\n",
       "       [  8.,  71.,   0.],\n",
       "       [ 18.,  85.,   0.],\n",
       "       [ 40.,  96.,   0.],\n",
       "       [ 61.,  98.,   0.],\n",
       "       [ 90.,  82.,   0.],\n",
       "       [107.,  65.,   0.],\n",
       "       [107.,  60.,   0.],\n",
       "       [ 19.,  51.,   0.],\n",
       "       [  2.,  46.,   1.],\n",
       "       [ 41.,  52.,   0.],\n",
       "       [ 41.,  31.,   1.],\n",
       "       [ 52.,  55.,   0.],\n",
       "       [ 52.,  31.,   1.],\n",
       "       [ 55.,  37.,   0.],\n",
       "       [ 55.,   3.,   0.],\n",
       "       [ 49.,   0.,   0.],\n",
       "       [ 34.,   2.,   0.],\n",
       "       [ 34.,  35.,   1.],\n",
       "       [ 30.,  36.,   0.],\n",
       "       [ 54.,  32.,   1.],\n",
       "       [ 56.,  31.,   0.],\n",
       "       [ 78.,  61.,   0.],\n",
       "       [ 77.,  32.,   0.],\n",
       "       [ 68.,  10.,   0.],\n",
       "       [ 63.,   4.,   0.],\n",
       "       [ 50.,   2.,   1.],\n",
       "       [ 29.,  14.,   0.],\n",
       "       [ 29.,  14.,   1.],\n",
       "       [140.,  51.,   0.],\n",
       "       [143.,  65.,   0.],\n",
       "       [156.,  81.,   0.],\n",
       "       [185.,  99.,   0.],\n",
       "       [205., 103.,   0.],\n",
       "       [217.,  99.,   0.],\n",
       "       [237.,  80.,   0.],\n",
       "       [254.,  40.,   0.],\n",
       "       [255.,  32.,   0.],\n",
       "       [251.,  29.,   1.]], dtype=float32)"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of what the array looks like\n",
    "pic_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.18431373, 0.        ],\n",
       "       [0.03137255, 0.2784314 , 0.        ],\n",
       "       [0.07058824, 0.33333334, 0.        ],\n",
       "       [0.15686275, 0.3764706 , 0.        ],\n",
       "       [0.23921569, 0.38431373, 0.        ],\n",
       "       [0.3529412 , 0.32156864, 0.        ],\n",
       "       [0.41960785, 0.25490198, 0.        ],\n",
       "       [0.41960785, 0.23529412, 0.        ],\n",
       "       [0.07450981, 0.2       , 0.        ],\n",
       "       [0.00784314, 0.18039216, 1.        ],\n",
       "       [0.16078432, 0.20392157, 0.        ],\n",
       "       [0.16078432, 0.12156863, 1.        ],\n",
       "       [0.20392157, 0.21568628, 0.        ],\n",
       "       [0.20392157, 0.12156863, 1.        ],\n",
       "       [0.21568628, 0.14509805, 0.        ],\n",
       "       [0.21568628, 0.01176471, 0.        ],\n",
       "       [0.19215687, 0.        , 0.        ],\n",
       "       [0.13333334, 0.00784314, 0.        ],\n",
       "       [0.13333334, 0.13725491, 1.        ],\n",
       "       [0.11764706, 0.14117648, 0.        ],\n",
       "       [0.21176471, 0.1254902 , 1.        ],\n",
       "       [0.21960784, 0.12156863, 0.        ],\n",
       "       [0.30588236, 0.23921569, 0.        ],\n",
       "       [0.3019608 , 0.1254902 , 0.        ],\n",
       "       [0.26666668, 0.03921569, 0.        ],\n",
       "       [0.24705882, 0.01568628, 0.        ],\n",
       "       [0.19607843, 0.00784314, 1.        ],\n",
       "       [0.11372549, 0.05490196, 0.        ],\n",
       "       [0.11372549, 0.05490196, 1.        ],\n",
       "       [0.54901963, 0.2       , 0.        ],\n",
       "       [0.56078434, 0.25490198, 0.        ],\n",
       "       [0.6117647 , 0.31764707, 0.        ],\n",
       "       [0.7254902 , 0.3882353 , 0.        ],\n",
       "       [0.8039216 , 0.40392157, 0.        ],\n",
       "       [0.8509804 , 0.3882353 , 0.        ],\n",
       "       [0.92941177, 0.3137255 , 0.        ],\n",
       "       [0.99607843, 0.15686275, 0.        ],\n",
       "       [1.        , 0.1254902 , 0.        ],\n",
       "       [0.9843137 , 0.11372549, 1.        ]], dtype=float32)"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize the data in pic_array\n",
    "\n",
    "lowest_val = np.min(pic_array[:, :2])\n",
    "highest_val = np.max(pic_array[:, :2])\n",
    "\n",
    "value_range = highest_val - lowest_val\n",
    "\n",
    "# avoid divide by zero\n",
    "\n",
    "if value_range == 0:\n",
    "    value_range = 1\n",
    "    \n",
    "pic_array[:, :2] = pic_array[:, :2]/value_range\n",
    "\n",
    "pic_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pic_array[1:, 0:2] -= pic_array[0:-1, 0:2]\n",
    "# pic_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def change_pic_from_dict_to_array(df):\n",
    "#     new_df = []\n",
    "#     for i in range(df.shape[0]):\n",
    "#         picture = df.iloc[i]\n",
    "        \n",
    "#         # find the length of all the individual drawings of the picture\n",
    "#         sketch_length = []\n",
    "#         for draw in picture:\n",
    "#             sketch_length.append(len(draw[0]))\n",
    "\n",
    "#         total_points = sum(sketch_length)\n",
    "        \n",
    "#         # make a blank array that takes the x, y and end points of the picture\n",
    "\n",
    "#         pic_array = np.zeros((total_points, 3), dtype = np.float32)\n",
    "        \n",
    "#         # go through each line of drawing and put it as the x and y values of the empty array.\n",
    "#         # if at the last list, mark the 3rd column as 1 (1 = end).\n",
    "\n",
    "#         position = 0\n",
    "\n",
    "#         for draw in picture:\n",
    "#             for i in [0, 1]:\n",
    "#                 pic_array[position:(position + len(draw[0])), i] = draw[i]\n",
    "#             position += len(draw[0])\n",
    "#             pic_array[position-1, 2] = 1\n",
    "\n",
    "#         # Normalize the data in pic_array\n",
    "\n",
    "#         lowest_val = np.min(pic_array[:, :2])\n",
    "#         highest_val = np.max(pic_array[:, :2])\n",
    "\n",
    "#         value_range = highest_val - lowest_val\n",
    "\n",
    "#         # avoid divide by zero\n",
    "\n",
    "#         if value_range == 0:\n",
    "#             value_range = 1\n",
    "\n",
    "#         pic_array[:, :2] = pic_array[:, :2]/value_range\n",
    "        \n",
    "#         new_df.append(pic_array)\n",
    "        \n",
    "#     return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def change_pic_from_dict_to_array_test(df):\n",
    "    \n",
    "#     for i in range(df.shape[0]):\n",
    "#         picture = df.iloc[i]\n",
    "        \n",
    "#         # find the length of all the individual drawings of the picture\n",
    "#         sketch_length = []\n",
    "#         for draw in picture:\n",
    "#             sketch_length.append(len(draw[0]))\n",
    "\n",
    "#         total_points = sum(sketch_length)\n",
    "        \n",
    "#         # make a blank array that takes the x, y and end points of the picture\n",
    "\n",
    "#         pic_array = np.zeros((total_points, 3), dtype = np.float32)\n",
    "        \n",
    "#         # go through each line of drawing and put it as the x and y values of the empty array.\n",
    "#         # if at the last list, mark the 3rd column as 1 (1 = end).\n",
    "\n",
    "#         position = 0\n",
    "\n",
    "#         for draw in picture:\n",
    "#             for i in [0, 1]:\n",
    "#                 pic_array[position:(position + len(draw[0])), i] = draw[i]\n",
    "#             position += len(draw[0])\n",
    "#             pic_array[position-1, 2] = 1\n",
    "\n",
    "#         # Normalize the data in pic_array\n",
    "\n",
    "#         lowest_val = np.min(pic_array[:, :2])\n",
    "#         highest_val = np.max(pic_array[:, :2])\n",
    "\n",
    "#         value_range = highest_val - lowest_val\n",
    "\n",
    "#         # avoid divide by zero\n",
    "\n",
    "#         if value_range == 0:\n",
    "#             value_range = 1\n",
    "\n",
    "#         pic_array[:, :2] = pic_array[:, :2]/value_range\n",
    "        \n",
    "#     return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get longest length of drawings\n",
    "\n",
    "def longest_stroke(df):\n",
    "    \n",
    "    drawing_length = []\n",
    "    for i in range(df.shape[0]):\n",
    "        picture = df.iloc[i]\n",
    "        \n",
    "        # find the length of all the individual drawings of the picture\n",
    "        sketch_length = []\n",
    "        for draw in picture:\n",
    "            sketch_length.append(len(draw[0]))\n",
    "\n",
    "        total_points = sum(sketch_length)\n",
    "        drawing_length.append(total_points)\n",
    "        \n",
    "#     print(drawing_length)\n",
    "\n",
    "    return np.max(drawing_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_pic_from_dict_to_array(df, max_sketch_length):\n",
    "    \n",
    "    pic_final = np.zeros((df.shape[0], max_sketch_length, 3), dtype = np.float32)\n",
    "    \n",
    "    for i in range(df.shape[0]):\n",
    "        \n",
    "        picture = df.iloc[i]\n",
    "        \n",
    "        # find the length of all the individual drawings of the picture\n",
    "#         sketch_length = []\n",
    "#         for draw in picture:\n",
    "#             sketch_length.append(len(draw[0]))\n",
    "\n",
    "#         total_points = sum(sketch_length)\n",
    "        \n",
    "        # make a blank array that takes the x, y and end points of the picture\n",
    "\n",
    "        pic_array = np.zeros((max_sketch_length, 3), dtype = np.float32)\n",
    "        \n",
    "        # go through each line of drawing and put it as the x and y values of the empty array.\n",
    "        # if at the last list, mark the 3rd column as 1 (1 = end).\n",
    "\n",
    "        position = 0\n",
    "\n",
    "        for draw in picture:\n",
    "            for i in [0, 1]:\n",
    "                pic_array[position:(position + len(draw[0])), i] = draw[i]\n",
    "            position += len(draw[0])\n",
    "            pic_array[position-1, 2] = 1\n",
    "\n",
    "        # Normalize the data in pic_array\n",
    "\n",
    "        lowest_val = np.min(pic_array[:, :2])\n",
    "        highest_val = np.max(pic_array[:, :2])\n",
    "\n",
    "        value_range = highest_val - lowest_val\n",
    "\n",
    "        # avoid divide by zero\n",
    "\n",
    "        if value_range == 0:\n",
    "            value_range = 1\n",
    "\n",
    "        pic_array[:, :2] = pic_array[:, :2]/value_range\n",
    "        \n",
    "        pic_final[i] = pic_array\n",
    "        \n",
    "    return pic_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "327"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_train_x = longest_stroke(train_x)\n",
    "max_test_x = longest_stroke(test_x)\n",
    "max_test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450, 327, 3)"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_final = change_pic_from_dict_to_array(train_x, max_train_x)\n",
    "test_x_final = change_pic_from_dict_to_array(test_x, max_test_x)\n",
    "test_x_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.45882353, 0.24313726, 0.        ],\n",
       "       [0.41568628, 0.24313726, 0.        ],\n",
       "       [0.29411766, 0.35686275, 0.        ],\n",
       "       [0.26666668, 0.40392157, 0.        ],\n",
       "       [0.23921569, 0.45882353, 0.        ],\n",
       "       [0.23529412, 0.60784316, 0.        ],\n",
       "       [0.26666668, 0.6745098 , 0.        ],\n",
       "       [0.31764707, 0.7176471 , 0.        ],\n",
       "       [0.38039216, 0.73333335, 0.        ],\n",
       "       [0.5294118 , 0.7411765 , 0.        ],\n",
       "       [0.5921569 , 0.7176471 , 0.        ],\n",
       "       [0.6784314 , 0.65882355, 0.        ],\n",
       "       [0.7176471 , 0.5647059 , 0.        ],\n",
       "       [0.7176471 , 0.49411765, 0.        ],\n",
       "       [0.5411765 , 0.3372549 , 0.        ],\n",
       "       [0.5411765 , 0.21176471, 0.        ],\n",
       "       [0.5019608 , 0.16470589, 0.        ],\n",
       "       [0.47843137, 0.16470589, 0.        ],\n",
       "       [0.47843137, 0.18431373, 0.        ],\n",
       "       [0.5764706 , 0.16862746, 0.        ],\n",
       "       [0.76862746, 0.07843138, 0.        ],\n",
       "       [0.87058824, 0.        , 0.        ],\n",
       "       [0.9647059 , 0.16470589, 1.        ],\n",
       "       [0.6039216 , 0.45490196, 0.        ],\n",
       "       [0.7647059 , 0.39215687, 0.        ],\n",
       "       [0.9372549 , 0.36078432, 0.        ],\n",
       "       [0.95686275, 0.3882353 , 0.        ],\n",
       "       [0.972549  , 0.45882353, 0.        ],\n",
       "       [1.        , 0.5137255 , 1.        ],\n",
       "       [0.6745098 , 0.7019608 , 0.        ],\n",
       "       [0.7254902 , 0.7058824 , 0.        ],\n",
       "       [0.9647059 , 0.79607844, 0.        ],\n",
       "       [0.9647059 , 0.8235294 , 0.        ],\n",
       "       [0.9254902 , 0.9098039 , 1.        ],\n",
       "       [0.2784314 , 0.34117648, 0.        ],\n",
       "       [0.06666667, 0.13333334, 0.        ],\n",
       "       [0.04705882, 0.15294118, 0.        ],\n",
       "       [0.        , 0.32941177, 1.        ],\n",
       "       [0.3647059 , 0.5411765 , 0.        ],\n",
       "       [0.29803923, 0.5411765 , 0.        ],\n",
       "       [0.07450981, 0.6       , 0.        ],\n",
       "       [0.06666667, 0.7058824 , 0.        ],\n",
       "       [0.08235294, 0.7411765 , 1.        ],\n",
       "       [0.41960785, 0.73333335, 0.        ],\n",
       "       [0.29411766, 0.85882354, 0.        ],\n",
       "       [0.21960784, 0.90588236, 0.        ],\n",
       "       [0.32156864, 0.9607843 , 1.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_final[1, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.45882353, 0.24313726, 0.        ],\n",
       "        [0.41568628, 0.24313726, 0.        ],\n",
       "        [0.29411766, 0.35686275, 0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Conv1D(5, kernel_size=300, activation='relu'))\n",
    "model.add(tf.keras.layers.Conv1D(64, kernel_size=20, activation='relu'))\n",
    "model.add(tf.keras.layers.Conv1D(64, kernel_size=9, activation='relu'))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(680, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(category_count, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_41 (Conv1D)           (None, 28, 5)             4505      \n",
      "_________________________________________________________________\n",
      "conv1d_42 (Conv1D)           (None, 9, 64)             6464      \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 1, 64)             36928     \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 680)               44200     \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 15)                10215     \n",
      "=================================================================\n",
      "Total params: 102,312\n",
      "Trainable params: 102,312\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-606-f9cf58f6cd7b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    646\u001b[0m         \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 648\u001b[1;33m         shuffle=shuffle)\n\u001b[0m\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2344\u001b[0m     \u001b[1;31m# First, we build the model on the fly if necessary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2345\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2346\u001b[1;33m       \u001b[0mall_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_model_with_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2347\u001b[0m       \u001b[0mis_build_called\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2348\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_build_model_with_inputs\u001b[1;34m(self, inputs, targets)\u001b[0m\n\u001b[0;32m   2570\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2571\u001b[0m       \u001b[0mcast_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2572\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2573\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mprocessed_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_dict_inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2574\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_set_inputs\u001b[1;34m(self, inputs, outputs, training)\u001b[0m\n\u001b[0;32m   2645\u001b[0m         \u001b[0mfirst\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0misn\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mFeatureLayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2646\u001b[0m     \"\"\"\n\u001b[1;32m-> 2647\u001b[1;33m     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_input_attrs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2648\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2649\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_set_input_attrs\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2684\u001b[0m         \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2685\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2686\u001b[1;33m         \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2687\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_input_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "model.fit(train_x_array, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get values from softmax\n",
    "\n",
    "model.predict(pict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the classification model \n",
    "\n",
    "# pass data through convolutional layers\n",
    "\n",
    "convoluted_input = train_x.shape[0] # based on train_x data\n",
    "num_convolutions =  # filter values\n",
    "length_convolutions = 10 # kernel values\n",
    "\n",
    "# normalize picture data\n",
    "convoluted_input = tf.keras.layers.BatchNormalization(convoluted_input, trainable = False)\n",
    "\n",
    "# create model\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# 1D convolution on images\n",
    "model.add(tf.keras.layers.Conv1D(filters = num_convolutions,\n",
    "                           kernel_size = length_convolutions,\n",
    "                           strides = 1,\n",
    "                           activation = None, \n",
    "                           use_bias = True))\n",
    "\n",
    "#model.add(tf.keras.layers.Lambda(lambda x: tf.expand_dims(model.output, axis=-1)))\n",
    "\n",
    "# re-evaluate size / convolution of image\n",
    "\n",
    "num_convolutions = 6 # filter values\n",
    "length_convolutions = 8 # kernel values\n",
    "\n",
    "# 1D convolution on images\n",
    "model.add(tf.keras.layers.Conv1D(filters = num_convolutions,\n",
    "                           kernel_size = length_convolutions,\n",
    "                           strides = 1,\n",
    "                           activation = None, \n",
    "                           use_bias = True))\n",
    "\n",
    "# re-evaluate size / convolution of image\n",
    "num_convolutions = 14 # filter values\n",
    "length_convolutions = 5 # kernel values\n",
    "\n",
    "# 1D convolution on images\n",
    "model.add(tf.keras.layers.Conv1D(filters = num_convolutions,\n",
    "                           kernel_size = length_convolutions,\n",
    "                           strides = 1,\n",
    "                           activation = None, \n",
    "                           use_bias = True))\n",
    "\n",
    "######################### end ###############################\n",
    "\n",
    "# flatten and classify\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "model.add(tf.keras.layers.Lambda(lambda x: tf.expand_dims(model.output, axis=-1)))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(15, activation = 'softmax'))\n",
    "\n",
    "######################### can potentially add movie classification to this model here\n",
    "\n",
    "model.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fname = \"shark_1.png\"\n",
    "\n",
    "img = plt.imread(fname)\n",
    "plt.imshow(img)\n",
    "\n",
    "# numRows, numCols, numChannels = img.shape\n",
    "# numPixels = numRows * numCols\n",
    "\n",
    "# numFeatures = 5\n",
    "\n",
    "# pic_array = np.zeros((numPixels, numFeatures))\n",
    "\n",
    "# idx = 0\n",
    "\n",
    "# for i in range(numRows):\n",
    "#     for j in range(numCols):\n",
    "        \n",
    "#         pic_array[idx,0:3] = img[i,j,:]\n",
    "#         pic_array[idx,3] = i\n",
    "#         pic_array[idx,4] = j\n",
    "        \n",
    "#         idx = idx + 1\n",
    "\n",
    "# pic_array = np.double(X)\n",
    "# means = np.mean(X, axis = 0)\n",
    "# standardDevs = np.std(X, axis = 0)\n",
    "\n",
    "# pic_array = (X-means)/standardDevs #normalizing the data\n",
    "means = np.mean(img)\n",
    "standardDevs = np.std(img)\n",
    "\n",
    "img = (img-means)/standardDevs #normalizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 432, 4)"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shapes = features[\"shape\"]\n",
    "# lengths = tf.squeeze(\n",
    "#     tf.slice(shapes, begin=[0, 0], size=[params[\"batch_size\"], 1]))\n",
    "# inks = tf.reshape(\n",
    "#     tf.sparse_tensor_to_dense(features[\"ink\"]),\n",
    "#     [params[\"batch_size\"], -1, 3])\n",
    "# if targets is not None:\n",
    "#   targets = tf.squeeze(targets)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162, 32, 32, 3)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pic_label = ['shark']\n",
    "pic_label = pd.DataFrame(pic_label)\n",
    "imgx = img.shape[0]\n",
    "imgy = img.shape[1]\n",
    "imgz = img.shape[2]\n",
    "img = np.reshape(img, (-1, 32, 32, 3))\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 680)               2785960   \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 680)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 15)                10215     \n",
      "=================================================================\n",
      "Total params: 2,815,567\n",
      "Trainable params: 2,815,567\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(680, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(category_count, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input arrays should have the same number of samples as target arrays. Found 162 input samples and 1 target samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-253-578b23336834>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m model.fit(x=img, y=pic_label,\n\u001b[0;32m      2\u001b[0m           \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m           epochs = 22)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    646\u001b[0m         \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 648\u001b[1;33m         shuffle=shuffle)\n\u001b[0m\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2381\u001b[0m         \u001b[0mis_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2382\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2383\u001b[1;33m         batch_size=batch_size)\n\u001b[0m\u001b[0;32m   2384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2385\u001b[0m   def _standardize_tensors(self, x, y, sample_weight, run_eagerly, dict_inputs,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_tensors\u001b[1;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[0;32m   2483\u001b[0m       \u001b[1;31m# Check that all arrays have the same length.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2484\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_distribution_strategy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2485\u001b[1;33m         \u001b[0mtraining_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_array_lengths\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2486\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mrun_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2487\u001b[0m           \u001b[1;31m# Additional checks to avoid users mistakenly using improper loss fns.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mcheck_array_lengths\u001b[1;34m(inputs, targets, weights)\u001b[0m\n\u001b[0;32m    742\u001b[0m                      \u001b[1;34m'the same number of samples as target arrays. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    743\u001b[0m                      \u001b[1;34m'Found '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' input samples '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 744\u001b[1;33m                      'and ' + str(list(set_y)[0]) + ' target samples.')\n\u001b[0m\u001b[0;32m    745\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset_w\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m     raise ValueError('All sample_weight arrays should have '\n",
      "\u001b[1;31mValueError\u001b[0m: Input arrays should have the same number of samples as target arrays. Found 162 input samples and 1 target samples."
     ]
    }
   ],
   "source": [
    "model.fit(x=img, y=pic_label,\n",
    "          batch_size = 32,\n",
    "          epochs = 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'iloc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-264-dad9a066b7a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtrain_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1050\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'iloc'"
     ]
    }
   ],
   "source": [
    "train_x = train_x.reshape(1, 1050, 1, 1)\n",
    "train_x.iloc[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer conv2d_23 is incompatible with the layer: expected ndim=4, found ndim=3. Full shape received: [None, 1, 1050]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-261-0eca575d92d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# 1D convolution on images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m model.add(tf.keras.layers.Conv2D(32, kernel_size = (3,3), strides = 1, activation = None, use_bias = True,\n\u001b[1;32m---> 13\u001b[1;33m                                  input_shape = (input_l, input_w)))\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'rmsprop'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    183\u001b[0m           \u001b[1;31m# and create the node connecting the current layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m           \u001b[1;31m# to the input layer we just created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m           \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m           \u001b[0mset_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    735\u001b[0m         \u001b[1;31m# are casted, not before.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    736\u001b[0m         input_spec.assert_input_compatibility(self.input_spec, inputs,\n\u001b[1;32m--> 737\u001b[1;33m                                               self.name)\n\u001b[0m\u001b[0;32m    738\u001b[0m         if (any(isinstance(x, ragged_tensor.RaggedTensor) for x in input_list)\n\u001b[0;32m    739\u001b[0m             and self._supports_ragged_inputs is False):  # pylint: disable=g-bool-id-comparison\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    175\u001b[0m                          \u001b[1;34m'expected ndim='\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', found ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m                          \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'. Full shape received: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m                          str(x.shape.as_list()))\n\u001b[0m\u001b[0;32m    178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m       \u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndims\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer conv2d_23 is incompatible with the layer: expected ndim=4, found ndim=3. Full shape received: [None, 1, 1050]"
     ]
    }
   ],
   "source": [
    "# normalize picture data\n",
    "\n",
    "input_l = train_x.shape[0]\n",
    "input_w = train_x.shape[1]\n",
    "\n",
    "convoluted_input = tf.keras.layers.BatchNormalization(1, trainable = False)\n",
    "\n",
    "# create model\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# 1D convolution on images\n",
    "model.add(tf.keras.layers.Conv2D(32, kernel_size = (3,3), strides = 1, activation = None, use_bias = True,\n",
    "                                 input_shape = (input_l, input_w)))\n",
    "\n",
    "model.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "# predictions = model.fit(train_x, train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "x_train = x_train/255.0\n",
    "x_test = x_test/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(6, (3,3), activation = 'relu', input_shape = (28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Conv2D(14, (3,3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(10, activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 3, 0, 2, 7, 2, 5, 5], dtype=uint8)"
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_26 (Conv2D)           (None, 26, 26, 6)         60        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 13, 13, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 11, 11, 14)        770       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 5, 5, 14)          0         \n",
      "_________________________________________________________________\n",
      "flatten_24 (Flatten)         (None, 350)               0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 64)                22464     \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 23,944\n",
      "Trainable params: 23,944\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape((60000, 28, 28, 1))\n",
    "x_test = x_test.reshape((10000, 28, 28, 1))\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 31s 520us/sample - loss: 0.6065 - accuracy: 0.7837\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 31s 518us/sample - loss: 0.4153 - accuracy: 0.8513- loss: 0.4153 - accuracy: 0.\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 36s 596us/sample - loss: 0.3685 - accuracy: 0.8679\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 33s 553us/sample - loss: 0.3384 - accuracy: 0.8786\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 35s 585us/sample - loss: 0.3157 - accuracy: 0.8866\n",
      "10000/10000 [==============================] - 4s 399us/sample - loss: 0.3622 - accuracy: 0.8637 - loss: 0.3646 - accu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3622121031284332, 0.8637)"
      ]
     },
     "execution_count": 644,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs = 5, batch_size = 64)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-619-ee4eb89e67ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "val = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.8736963e-06, 1.4511286e-07, 1.3656431e-06, 2.5868229e-07,\n",
       "       1.2391682e-06, 2.8979639e-03, 4.6316571e-05, 1.2361527e-02,\n",
       "       5.4407478e-03, 9.7924358e-01], dtype=float32)"
      ]
     },
     "execution_count": 645,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.988371, (array([7], dtype=int64),))"
      ]
     },
     "execution_count": 634,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.where(val[60] == np.max(val[60]))\n",
    "np.max(val[60]), idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 633,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_val(model, index_test_df, test_df):\n",
    "    val = model.predict(test_df)\n",
    "    idx = np.where(val[index_test_df] == np.max(val[index_test_df]))\n",
    "    \n",
    "    # what keyword is at idx? return that. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_movie(movies, pic_df, img_list):\n",
    "    predict = []\n",
    "    for i in img_list:\n",
    "        predict.append(predict_val(model, i, pic_df))\n",
    "    \n",
    "    # keywords in predict. using this, get the movie/movies\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
